
### Regress and Fundamental Value
<br>
The most pressing implication of the Infinite Regress 
problem to me is how it seems to invalidate all concepts of meaning and morality. 
And in referring to "meaning" and "morality", what I refer to is not 
concepts of "higher meaning/morality", but rather any meaning, 
significance, or value at all, following from the idea that any theory of 
morality, a theory of preferable action, is really first and foremost a theory of value with
right/wrong deriving only from the value prescribed to the action. As an experiment,
one can ask themselves why they care about some particular thing/idea. After a few whys, 
one ends up at some fundamental belief, like "utility, defined as pleasure minus pain, is valuable,
and a meaningful goal is to maximize the aggregate utility". But if one tries to justify 
any further beyond these kinds of beliefs, justification seems impossible, 
at least in the sense of justifying why it should be advocated for
(as in, one might be able to explain why they ended up with that as an assumption, but 
one cannot explain why the assumption should be advocated for or believed in).
<br><br>
Immediately, this leads to some very interesting results. For instance, it seems that 
no action can be considered categorically unjust. If someone were to come up to me, and say 
"I want to murder you, why should I not be able to?", I could regress an argument down to say, 
"you should value the utility of all individuals", but the murderer could simply reject that claim and I would 
have no rebuttal to his rejection. This is also quite different from the way that "moral subjectivism" might argue
for an absence of "categorical right/wrong", since one can still theoretically unify the right/wrong in that case with an 
overarching theory. For instance, people from country X may not like if you do Y, while people from counry Z really enjoy it,
so rather than making an attempt at categorically saying "do Y or don't", you can just say "the categorical rule is to
do what makes people happiest".
<br><br>
In an individually pressing way, one is left with 
the surprising question of why you should even care about your own happiness. This naturally
leads to the interesting question of whether finding your own happiness needs to be justified,
which leads to further interesting questions regarding free will. For instance, could we avoid 
the need for justification by asserting that we are "programmed" to care about our own happiness,
and there is no use discussing whether we should or shouldn't care about it? Though even in spite of
such an argument, it doesn't seem like that fact could give any "meaning/value" to that programming.
There may be a way "out" if one converts concepts of happiness/meaning/value into measurable concepts,
though this way out still has the consequence of voiding our traditional sense of meaning/value. 
If one moves towards defining happiness/value/what we care about as what we would prefer to do/pursue,
then we can restore some kind of coherence "by definition", but this still leaves the original,
intuitive senses of meaning/value as void concepts.
<br><br>
It seems more or less that the very idea of a "preferable state" for the universe might not make
any intrinsic sense, and can be thought of like any number of things that don't make sense
until assumptions are introduced. For instance, the height of a volume of water is 
a meaningless concept unless one assumes some characteristics about what shape the volume takes.
Likewise, a "preferable state" does not exist until one makes assumptions about what 
is or isn't valuable. But it seems that unlike in the water case, where 
we can openly acknowledge the assumption and reason through what use the conclusions have given
that assumption, our intuitive sense of value/meaning is deeply founded in the idea that 
the value/meaning is not an assumption, and actually a intrinsic fact of the universe.
<br><br>
Given that we can reduce our values to assumptions, we seem to be left with
either nihilism or the unclear task of how to find intrinsic value in assumptions.


 

